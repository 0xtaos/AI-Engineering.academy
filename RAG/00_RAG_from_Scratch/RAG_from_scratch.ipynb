{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG: Retrieval-Augmented Generation\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/adithya-s-k/AI-Engineering.academy/blob/main/RAG/00_RAG_from_Scratch/RAG_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "\n",
    "- **R**: **Retrieval** - Fetch the right external content.\n",
    "- **A**: **Augmentation** - Modify the prompt to pass content form Retrival Stage\n",
    "- **G**: **Generation** - Generate the final response using the LLM.\n",
    "\n",
    "### Programmatic Stages:\n",
    "\n",
    "#### 1. Data Ingestion:\n",
    "   - Parse PDF and extract text.\n",
    "   - Perform text chunking.\n",
    "   - Set up the database.\n",
    "   - Populate the database with parsed data.\n",
    "\n",
    "#### 2. Retrieval:\n",
    "   - Take the user query as input.\n",
    "   - Perform similarity search across the stored data.\n",
    "   - Retrieve the most relevant chunks of information.\n",
    "   \n",
    "#### 3. Augmentation:\n",
    "   - Augment the prompt by incorporating relevant chunks of retrieved data.\n",
    "   - Adjust the prompt through prompt engineering to optimize for clarity and context.\n",
    "\n",
    "#### 4. Generation:\n",
    "   - Use the enhanced prompt to generate a response using the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -q sentence-transformers\n",
    "# !pip install -q wikipedia-api\n",
    "# !pip install -q numpy\n",
    "# !pip install -q scipy\n",
    "# !pip install openai\n",
    "# !pip install rich\n",
    "!pip install pypdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import openai\n",
    "from rich import print\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "import textwrap\n",
    "from wikipediaapi import Wikipedia\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_path):\n",
    "    \"\"\"\n",
    "    Load document from a given file path. Supports PDF and text files.\n",
    "    \"\"\"\n",
    "    _, file_extension = os.path.splitext(file_path)\n",
    "    \n",
    "    if file_extension.lower() == '.pdf':\n",
    "        with open(file_path, 'rb') as file:\n",
    "            pdf_reader = PyPDF2.PdfReader(file)\n",
    "            text = \"\"\n",
    "            for page in pdf_reader.pages:\n",
    "                text += page.extract_text()\n",
    "    elif file_extension.lower() == '.txt':\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    elif file_extension.lower() == '.md':\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a PDF or text file.\")\n",
    "    \n",
    "    return text\n",
    "\n",
    "data = load_document(\"../data/md/attention_is_all_you_need.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=100, overlap=20):\n",
    "    \"\"\"\n",
    "    Split the text into chunks based on the number of words and word overlap.\n",
    "    \"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    return chunks\n",
    "\n",
    "chunked_data = chunk_text(data)\n",
    "\n",
    "chunked_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of chunks\n",
    "def print_chunks(chunks):\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        print(f\"Chunk {i + 1}:\")\n",
    "        print(chunk)\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "print_chunks(chunked_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Up embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up similarity function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualise embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "embed chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "store the vectors/embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrival"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similarity search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get top K results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmenting Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modifying system prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set up llm provider"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
