{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAPTOR Implementation:\n",
    "A Comprehensive Guide to Recursive Abstractive Processing for Tree Organized Retrieval\n",
    "\n",
    "<a href=\"https://github.com/adithya-s-k/AI-Engineering.academy\">\n",
    "<img src=\"https://raw.githubusercontent.com/adithya-s-k/AI-Engineering.academy/main/assets/banner.png\" width=\"50%\">\n",
    "</a>\n",
    "\n",
    "Welcome to the RAPTOR Implementation guide! This notebook introduces you to Recursive Abstractive Processing for Tree Organized Retrieval, a novel indexing and retrieving technique specifically designed for long-context language models. We'll provide a step-by-step walkthrough of implementing a RAPTOR system, focusing on its application to long-context documents.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "RAPTOR is an innovative approach that adapts a bottom-up strategy for indexing and retrieval of documents, particularly suited for long-context language models. By clustering and summarizing text segments recursively, RAPTOR creates a hierarchical tree structure that captures both high-level abstractions and detailed aspects of text. This technique is especially valuable for complex thematic queries and multi-step reasoning tasks in questioning and answering systems.\n",
    "\n",
    "## Getting Started\n",
    "\n",
    "To fully benefit from this notebook, you should have a good understanding of Python and be familiar with basic concepts of document indexing and retrieval. Don't worry if some advanced ideas are new to you – we'll guide you through each step of the RAPTOR process!\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "- Python 3.9+\n",
    "- Jupyter Notebook or JupyterLab\n",
    "- Familiarity with document indexing and retrieval concepts\n",
    "- Understanding of vector embeddings and clustering algorithms\n",
    "- Basic knowledge of natural language processing (NLP) concepts\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "Our notebook is structured into the following main sections:\n",
    "\n",
    "1. **Environment Set Up**: We'll guide you through setting up your Python environment with all the necessary libraries and dependencies for RAPTOR.\n",
    "\n",
    "2. **Document Chunking**: Learn how to segment large documents into manageable chunks suitable for embedding and processing.\n",
    "\n",
    "3. **Embedding Generation**: Understand how to generate embeddings for document chunks using various embedding models.\n",
    "\n",
    "4. **Clustering Algorithm Implementation**: Dive into the process of clustering reduced-dimension embeddings using appropriate algorithms.\n",
    "\n",
    "5. **Summarization Process**: Learn how to generate summaries for clustered chunks using large language models.\n",
    "\n",
    "6. **Recursive Tree Construction**: Understand how to recursively build the hierarchical tree structure by repeating the clustering and summarization process.\n",
    "\n",
    "7. **Retrieval Mechanism**: Explore how to perform efficient retrieval using the constructed tree structure.\n",
    "\n",
    "8. **Integration with Long-Context LLMs**: Learn how to incorporate RAPTOR outputs into prompts for long-context language models.\n",
    "\n",
    "\n",
    "By the end of this notebook, you'll have a deep understanding of RAPTOR and be able to implement this advanced technique for efficient document retrieval and utilization in long-context language model applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samarth/miniconda3/envs/cognitivelab/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, Dict, List, Optional\n",
    "import asyncio\n",
    "from enum import Enum\n",
    "\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    "    get_response_synthesizer,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "from llama_index.core.base.response.schema import Response\n",
    "from llama_index.core.base.base_retriever import BaseRetriever, QueryType\n",
    "from llama_index.core.bridge.pydantic import BaseModel, Field\n",
    "from llama_index.core.embeddings import BaseEmbedding\n",
    "from llama_index.core.ingestion import run_transformations\n",
    "from llama_index.core.llama_pack.base import BaseLlamaPack\n",
    "from llama_index.core.llms.llm import LLM\n",
    "from llama_index.core.response_synthesizers import BaseSynthesizer\n",
    "from llama_index.core.schema import (\n",
    "    BaseNode,\n",
    "    NodeWithScore,\n",
    "    QueryBundle,\n",
    "    TextNode,\n",
    "    TransformComponent,\n",
    ")\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    BasePydanticVectorStore,\n",
    ")\n",
    "from llama_index.packs.raptor.clustering import get_clusters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define prompt to summarize and the 2 query modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DEFAULT_SUMMARY_PROMPT = (\n",
    "    \"Summarize the provided text, including as many key details as needed.\"\n",
    ")\n",
    "\n",
    "\n",
    "class QueryModes(str, Enum):\n",
    "    \"\"\"Query modes.\"\"\"\n",
    "\n",
    "    tree_traversal = \"tree_traversal\"\n",
    "    collapsed = \"collapsed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This class defines a `SummaryModule` that uses a response synthesizer to generate summaries for clusters of documents asynchronously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummaryModule(BaseModel):\n",
    "    response_synthesizer: BaseSynthesizer = Field(description=\"LLM\")\n",
    "    summary_prompt: str = Field(\n",
    "        default=DEFAULT_SUMMARY_PROMPT,\n",
    "        description=\"Summary prompt.\",\n",
    "    )\n",
    "    num_workers: int = Field(\n",
    "        default=4, description=\"Number of workers to generate summaries.\"\n",
    "    )\n",
    "    show_progress: bool = Field(default=True, description=\"Show progress.\")\n",
    "\n",
    "    class Config:\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        llm: Optional[LLM] = None,\n",
    "        summary_prompt: str = DEFAULT_SUMMARY_PROMPT,\n",
    "        num_workers: int = 4,\n",
    "    ) -> None:\n",
    "        response_synthesizer = get_response_synthesizer(\n",
    "            response_mode=\"tree_summarize\", use_async=True, llm=llm\n",
    "        )\n",
    "        super().__init__(\n",
    "            response_synthesizer=response_synthesizer,\n",
    "            summary_prompt=summary_prompt,\n",
    "            num_workers=num_workers,\n",
    "        )\n",
    "\n",
    "    async def generate_summaries(\n",
    "        self, documents_per_cluster: List[List[BaseNode]]\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Generate summaries of documents per cluster.\n",
    "\n",
    "        Args:\n",
    "            documents_per_cluster (List[List[BaseNode]]): List of documents per cluster\n",
    "\n",
    "        Returns:\n",
    "            List[str]: List of summary for each cluster\n",
    "        \"\"\"\n",
    "        jobs = []\n",
    "        for documents in documents_per_cluster:\n",
    "            with_scores = [NodeWithScore(node=doc, score=1.0) for doc in documents]\n",
    "            jobs.append(\n",
    "                self.response_synthesizer.asynthesize(self.summary_prompt, with_scores)\n",
    "            )\n",
    "\n",
    "        lock = asyncio.Semaphore(self.num_workers)\n",
    "        responses = []\n",
    "\n",
    "        # run the jobs while limiting the number of concurrent jobs to num_workers\n",
    "        for job in jobs:\n",
    "            async with lock:\n",
    "                responses.append(await job)\n",
    "\n",
    "        return [str(response) for response in responses]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This class defines a `RaptorRetriever` that indexes and retrieves documents using a hierarchical tree structure. It supports both collapsed and tree traversal retrieval modes, and can generate summaries for clusters of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaptorRetriever(BaseRetriever):\n",
    "    \"\"\"Raptor indexing retriever.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        documents: List[BaseNode],\n",
    "        tree_depth: int = 3,\n",
    "        similarity_top_k: int = 2,\n",
    "        llm: Optional[LLM] = None,\n",
    "        embed_model: Optional[BaseEmbedding] = None,\n",
    "        vector_store: Optional[BasePydanticVectorStore] = None,\n",
    "        transformations: Optional[List[TransformComponent]] = None,\n",
    "        summary_module: Optional[SummaryModule] = None,\n",
    "        existing_index: Optional[VectorStoreIndex] = None,\n",
    "        mode: QueryModes = \"collapsed\",\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        super().__init__(\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.mode = mode\n",
    "        self.summary_module = summary_module or SummaryModule(llm=llm)\n",
    "        self.index = existing_index or VectorStoreIndex(\n",
    "            nodes=[],\n",
    "            storage_context=StorageContext.from_defaults(vector_store=vector_store),\n",
    "            embed_model=embed_model,\n",
    "            transformations=transformations,\n",
    "        )\n",
    "        self.tree_depth = tree_depth\n",
    "        self.similarity_top_k = similarity_top_k\n",
    "\n",
    "        if len(documents) > 0:\n",
    "            asyncio.run(self.insert(documents))\n",
    "\n",
    "    def _get_embeddings_per_level(self, level: int = 0) -> List[float]:\n",
    "        \"\"\"Retrieve embeddings per level in the abstraction tree.\n",
    "\n",
    "        Args:\n",
    "            level (int, optional): Target level. Defaults to 0 which stands for leaf nodes.\n",
    "\n",
    "        Returns:\n",
    "            List[float]: List of embeddings\n",
    "        \"\"\"\n",
    "        filters = MetadataFilters(filters=[MetadataFilter(\"level\", level)])\n",
    "\n",
    "        # kind of janky, but should work with any vector index\n",
    "        source_nodes = self.index.as_retriever(\n",
    "            similarity_top_k=10000, filters=filters\n",
    "        ).retrieve(\"retrieve\")\n",
    "\n",
    "        return [x.node for x in source_nodes]\n",
    "\n",
    "    async def insert(self, documents: List[BaseNode]) -> None:\n",
    "        \"\"\"Given a set of documents, this function inserts higher level of abstractions within the index.\n",
    "\n",
    "        For later retrieval\n",
    "\n",
    "        Args:\n",
    "            documents (List[BaseNode]): List of Documents\n",
    "        \"\"\"\n",
    "        embed_model = self.index._embed_model\n",
    "        transformations = self.index._transformations\n",
    "\n",
    "        cur_nodes = run_transformations(documents, transformations, in_place=False)\n",
    "        for level in range(self.tree_depth):\n",
    "            # get the embeddings for the current documents\n",
    "\n",
    "            if self._verbose:\n",
    "                print(f\"Generating embeddings for level {level}.\")\n",
    "\n",
    "            embeddings = await embed_model.aget_text_embedding_batch(\n",
    "                [node.get_content(metadata_mode=\"embed\") for node in cur_nodes]\n",
    "            )\n",
    "            assert len(embeddings) == len(cur_nodes)\n",
    "            id_to_embedding = {\n",
    "                node.id_: embedding for node, embedding in zip(cur_nodes, embeddings)\n",
    "            }\n",
    "\n",
    "            if self._verbose:\n",
    "                print(f\"Performing clustering for level {level}.\")\n",
    "\n",
    "            # cluster the documents\n",
    "            nodes_per_cluster = get_clusters(cur_nodes, id_to_embedding)\n",
    "\n",
    "            if self._verbose:\n",
    "                print(\n",
    "                    f\"Generating summaries for level {level} with {len(nodes_per_cluster)} clusters.\"\n",
    "                )\n",
    "            summaries_per_cluster = await self.summary_module.generate_summaries(\n",
    "                nodes_per_cluster\n",
    "            )\n",
    "\n",
    "            if self._verbose:\n",
    "                print(\n",
    "                    f\"Level {level} created summaries/clusters: {len(nodes_per_cluster)}\"\n",
    "                )\n",
    "\n",
    "            # replace the current nodes with their summaries\n",
    "            new_nodes = [\n",
    "                TextNode(\n",
    "                    text=summary,\n",
    "                    metadata={\"level\": level},\n",
    "                    excluded_embed_metadata_keys=[\"level\"],\n",
    "                    excluded_llm_metadata_keys=[\"level\"],\n",
    "                )\n",
    "                for summary in summaries_per_cluster\n",
    "            ]\n",
    "\n",
    "            # insert the nodes with their embeddings and parent_id\n",
    "            nodes_with_embeddings = []\n",
    "            for cluster, summary_doc in zip(nodes_per_cluster, new_nodes):\n",
    "                for node in cluster:\n",
    "                    node.metadata[\"parent_id\"] = summary_doc.id_\n",
    "                    node.excluded_embed_metadata_keys.append(\"parent_id\")\n",
    "                    node.excluded_llm_metadata_keys.append(\"parent_id\")\n",
    "                    node.embedding = id_to_embedding[node.id_]\n",
    "                    nodes_with_embeddings.append(node)\n",
    "\n",
    "            self.index.insert_nodes(nodes_with_embeddings)\n",
    "\n",
    "            # set the current nodes to the new nodes\n",
    "            cur_nodes = new_nodes\n",
    "\n",
    "        self.index.insert_nodes(cur_nodes)\n",
    "\n",
    "    async def collapsed_retrieval(self, query_str: str) -> Response:\n",
    "        \"\"\"Query the index as a collapsed tree -- i.e. a single pool of nodes.\"\"\"\n",
    "        return await self.index.as_retriever(\n",
    "            similarity_top_k=self.similarity_top_k\n",
    "        ).aretrieve(query_str)\n",
    "\n",
    "    async def tree_traversal_retrieval(self, query_str: str) -> Response:\n",
    "        \"\"\"Query the index as a tree, traversing the tree from the top down.\"\"\"\n",
    "        # get top k nodes for each level, starting with the top\n",
    "        parent_ids = None\n",
    "        nodes = []\n",
    "        level = self.tree_depth - 1\n",
    "        while level >= 0:\n",
    "            # retrieve nodes at the current level\n",
    "            if parent_ids is None:\n",
    "                nodes = await self.index.as_retriever(\n",
    "                    similarity_top_k=self.similarity_top_k,\n",
    "                    filters=MetadataFilters(\n",
    "                        filters=[MetadataFilter(key=\"level\", value=level)]\n",
    "                    ),\n",
    "                ).aretrieve(query_str)\n",
    "\n",
    "                parent_ids = [node.id_ for node in nodes]\n",
    "                if self._verbose:\n",
    "                    print(f\"Retrieved parent IDs from level {level}: {parent_ids!s}\")\n",
    "            # retrieve nodes that are children of the nodes at the previous level\n",
    "            elif parent_ids is not None and len(parent_ids) > 0:\n",
    "                nested_nodes = await asyncio.gather(\n",
    "                    *[\n",
    "                        self.index.as_retriever(\n",
    "                            similarity_top_k=self.similarity_top_k,\n",
    "                            filters=MetadataFilters(\n",
    "                                filters=[MetadataFilter(key=\"parent_id\", value=id_)]\n",
    "                            ),\n",
    "                        ).aretrieve(query_str)\n",
    "                        for id_ in parent_ids\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                nodes = [node for nested in nested_nodes for node in nested]\n",
    "\n",
    "                if self._verbose:\n",
    "                    print(f\"Retrieved {len(nodes)} from parents at level {level}.\")\n",
    "\n",
    "                level -= 1\n",
    "                parent_ids = None\n",
    "\n",
    "        return nodes\n",
    "\n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query and mode.\"\"\"\n",
    "        # not used, needed for type checking\n",
    "\n",
    "    def retrieve(\n",
    "        self, query_str_or_bundle: QueryType, mode: Optional[QueryModes] = None\n",
    "    ) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query and mode.\"\"\"\n",
    "        if isinstance(query_str_or_bundle, QueryBundle):\n",
    "            query_str = query_str_or_bundle.query_str\n",
    "        else:\n",
    "            query_str = query_str_or_bundle\n",
    "\n",
    "        return asyncio.run(self.aretrieve(query_str, mode or self.mode))\n",
    "\n",
    "    async def aretrieve(\n",
    "        self, query_str_or_bundle: QueryType, mode: Optional[QueryModes] = None\n",
    "    ) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes given query and mode.\"\"\"\n",
    "        if isinstance(query_str_or_bundle, QueryBundle):\n",
    "            query_str = query_str_or_bundle.query_str\n",
    "        else:\n",
    "            query_str = query_str_or_bundle\n",
    "\n",
    "        mode = mode or self.mode\n",
    "        if mode == \"tree_traversal\":\n",
    "            return await self.tree_traversal_retrieval(query_str)\n",
    "        elif mode == \"collapsed\":\n",
    "            return await self.collapsed_retrieval(query_str)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid mode: {mode}\")\n",
    "\n",
    "    def persist(self, persist_dir: str) -> None:\n",
    "        self.index.storage_context.persist(persist_dir=persist_dir)\n",
    "\n",
    "    @classmethod\n",
    "    def from_persist_dir(\n",
    "        cls: \"RaptorRetriever\",\n",
    "        persist_dir: str,\n",
    "        embed_model: Optional[BaseEmbedding] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"RaptorRetriever\":\n",
    "        storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
    "        return cls(\n",
    "            [],\n",
    "            existing_index=load_index_from_storage(\n",
    "                storage_context, embed_model=embed_model\n",
    "            ),\n",
    "            **kwargs,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This class defines a `RaptorPack` that initializes a `RaptorRetriever` with various parameters and provides methods to get modules and run retrieval queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RaptorPack(BaseLlamaPack):\n",
    "    \"\"\"Raptor pack.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        documents: List[BaseNode],\n",
    "        llm: Optional[LLM] = None,\n",
    "        embed_model: Optional[BaseEmbedding] = None,\n",
    "        vector_store: Optional[BasePydanticVectorStore] = None,\n",
    "        similarity_top_k: int = 2,\n",
    "        mode: QueryModes = \"collapsed\",\n",
    "        verbose: bool = True,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Init params.\"\"\"\n",
    "        self.retriever = RaptorRetriever(\n",
    "            documents,\n",
    "            embed_model=embed_model,\n",
    "            llm=llm,\n",
    "            similarity_top_k=similarity_top_k,\n",
    "            vector_store=vector_store,\n",
    "            mode=mode,\n",
    "            verbose=verbose,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    def get_modules(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get modules.\"\"\"\n",
    "        return {\n",
    "            \"retriever\": self.retriever,\n",
    "        }\n",
    "\n",
    "    def run(\n",
    "        self,\n",
    "        query: str,\n",
    "        mode: Optional[QueryModes] = None,\n",
    "    ) -> Any:\n",
    "        \"\"\"Run the pipeline.\"\"\"\n",
    "        return self.retriever.retrieve(query, mode=mode)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import OpenAI and llamaindex libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "from llama_index.core import Document, Settings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code defines functions to fetch markdown content from a given URL and create sample documents using the fetched content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Artificial intelligence\n",
      "\n",
      "URL Source: http://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "\n",
      "Published Time: 2001-10-08T16:55:49Z\n",
      "\n",
      "Markdown Content:\n",
      "Jump to content\n",
      "Main menu\n",
      "Search\n",
      "Appearance\n",
      "Cr \n",
      "\n",
      "Title: Starting a New CrewAI Project - Using Template - crewAI\n",
      "\n",
      "URL Source: https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/\n",
      "\n",
      "Markdown Content:\n",
      "[](https://github.com \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def fetch_markdown_content(url: str) -> str:\n",
    "    \"\"\"Fetch markdown content from the Jina Reader.\"\"\"\n",
    "    response = requests.get(f\"https://r.jina.ai/{url}\")\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    return response.text.strip()\n",
    "\n",
    "def create_sample_documents() -> List[Document]:\n",
    "    \"\"\"Create a list of sample documents by fetching markdown content from Jina Reader.\"\"\"\n",
    "    \n",
    "    urls = [\n",
    "        \"en.wikipedia.org/wiki/Artificial_intelligence\", \n",
    "        \"https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#customizing-your-project\"\n",
    "    ]\n",
    "    \n",
    "    documents = []\n",
    "    for url in urls:\n",
    "        markdown_text = fetch_markdown_content(url)\n",
    "        documents.append(Document(text=markdown_text))\n",
    "    \n",
    "    return documents\n",
    "\n",
    "sample_docs = create_sample_documents()\n",
    "for doc in sample_docs:\n",
    "    print(doc.text[:200], '\\n')  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This code initializes a `RaptorPack` with sample documents and the `gpt-4o-mini` language model. It then runs a series of test queries against the `RaptorPack` and prints the results, including the content and score of each retrieved node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for level 0.\n",
      "Performing clustering for level 0.\n",
      "Generating summaries for level 0 with 9 clusters.\n",
      "Level 0 created summaries/clusters: 9\n",
      "Generating embeddings for level 1.\n",
      "Performing clustering for level 1.\n",
      "Generating summaries for level 1 with 1 clusters.\n",
      "Level 1 created summaries/clusters: 1\n",
      "Generating embeddings for level 2.\n",
      "Performing clustering for level 2.\n",
      "Generating summaries for level 2 with 1 clusters.\n",
      "Level 2 created summaries/clusters: 1\n",
      "\n",
      "Query: What is artificial intelligence?\n",
      "Retrieved parent IDs from level 2: ['1de596a1-366f-4f6a-8a01-aa2cbd9f229c']\n",
      "Retrieved 1 from parents at level 2.\n",
      "Retrieved parent IDs from level 1: ['e60b28b2-2912-4188-9fee-171ce9884405']\n",
      "Retrieved 2 from parents at level 1.\n",
      "Retrieved parent IDs from level 0: ['db7f1f15-7990-4227-bf1f-6cfe44e4b3b5', '77164cf2-5fdf-4f43-88ca-32b77f145f84']\n",
      "Retrieved 4 from parents at level 0.\n",
      "Result 1:\n",
      "Content: Title: Artificial intelligence\n",
      "\n",
      "URL Source: http://en.wikipedia.org/wiki/Artificial_intelligence\n",
      "\n",
      "Published Time: 2001-10-08T16:55:49Z\n",
      "\n",
      "Markdown Content:\n",
      "Jump to content\n",
      "Main menu\n",
      "Search\n",
      "Appearance\n",
      "Create account\n",
      "Log in\n",
      "Personal tools\n",
      "Toggle the table of contents\n",
      "Artificial intelligence\n",
      "157 languages\n",
      "Article\n",
      "Talk\n",
      "Read\n",
      "View source\n",
      "View history\n",
      "Tools\n",
      "From Wikipedia, the free encyclopedia\n",
      "\"AI\" redirects here. For other uses, see AI (disambiguation), Artificial intelligence (disambiguation), and Intelligent agent.\n",
      "Part of a series on\n",
      "Artificial intelligence\n",
      "\n",
      "\n",
      "\n",
      "show\n",
      "Major goals\n",
      "\n",
      "\n",
      "show\n",
      "Approaches\n",
      "\n",
      "\n",
      "show\n",
      "Applications\n",
      "\n",
      "\n",
      "show\n",
      "Philosophy\n",
      "\n",
      "\n",
      "show\n",
      "History\n",
      "\n",
      "\n",
      "show\n",
      "Glossary\n",
      "\n",
      "vte\n",
      "\n",
      "Artificial intelligence (AI), in its broadest sense, is intelligence exhibited by machines, particularly computer systems. It is a field of research in computer science that develops and studies methods and software that enable machines to perceive their environment and use learning and intelligence to take actions that maximize their chances of achieving defined goals.[1] Such machines may be called AIs.\n",
      "\n",
      "Some high-profile applications of AI include advanced web search engines (e.g., Google Search); recommendation systems (used by YouTube, Amazon, and Netflix); interacting via human speech (e.g., Google Assistant, Siri, and Alexa); autonomous vehicles (e.g., Waymo); generative and creative tools (e.g., ChatGPT, Apple Intelligence, and AI art); and superhuman play and analysis in strategy games (e.g., chess and Go). However, many AI applications are not perceived as AI: \"A lot of cutting edge AI has filtered into general applications, often without being called AI because once something becomes useful enough and common enough it's not labeled AI anymore.\"[2][3]\n",
      "\n",
      "The various subfields of AI research are centered around particular goals and the use of particular tools. The traditional goals of AI research include reasoning, knowledge representation, planning, learning, natural language processing, perception, and support for robotics.[a] General intelligence—the ability to complete any task performable by a human on an at least equal level—is among the field's long-term goals.[4] To reach these goals, AI researchers have adapted and integrated a wide range of techniques, including search and mathematical optimization, formal logic, artificial neural networks, and methods based on statistics, operations research, and economics.[b] AI also draws upon psychology, linguistics, philosophy, neuroscience, and other fields.[5]\n",
      "\n",
      "Artificial intelligence was founded as an academic discipline in 1956,[6] and the field went through multiple cycles of optimism,[7][8] followed by periods of disappointment and loss of funding, known as AI winter.[9][10] Funding and interest vastly increased after 2012 when deep learning outperformed previous AI techniques.[11] This growth accelerated further after 2017 with the transformer architecture,[12] and by the 2020s hundreds of billions of dollars were being invested in AI (known as the \"AI boom\"). The widespread use of AI in the 21st century exposed several unintended consequences and harms in the present and raised concerns about its risks and the long-term effects in the future, prompting discussions about regulatory policies to ensure the safety and benefits of the technology.\n",
      "\n",
      "Goals\n",
      "\n",
      "The general problem of simulating (or creating) intelligence has been broken into subproblems. These consist of particular traits or capabilities that researchers expect an intelligent system to display. The traits described below have received the most attention and cover the scope of AI research.[a]\n",
      "\n",
      "Reasoning and problem-solving\n",
      "\n",
      "Early researchers developed algorithms that imitated step-by-step reasoning that humans use when they solve puzzles or make logical deductions.[13] By the late 1980s and 1990s, methods were developed for dealing with uncertain or incomplete information, employing concepts from probability and economics.[14]\n",
      "\n",
      "Many of these algorithms are insufficient for solving large reasoning problems because they experience a \"combinatorial explosion\": They become exponentially slower as the problems grow.[15] Even humans rarely use the step-by-step deduction that early AI research could model. They solve most of their problems using fast, intuitive judgments.[16] Accurate and efficient reasoning is an unsolved problem.\n",
      "\n",
      "Knowledge representation\n",
      "An ontology represents knowledge as a set of concepts within a domain and the relationships between those concepts.\n",
      "\n",
      "Knowledge representation and knowledge engineering[17] allow AI programs to answer questions intelligently and make deductions about real-world facts. Formal knowledge representations are used in content-based indexing and retrieval,[18] scene interpretation,[19] clinical decision support,[20] knowledge discovery (mining \"interesting\" and actionable inferences from large databases),[21] and other areas.[22]\n",
      "\n",
      "A knowledge base is a body of knowledge represented in a form that can be used by a program.\n",
      "Score: 0.8782760023374744\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Content: The deployment of AI may be overseen by a Chief automation officer (CAO).\n",
      "\n",
      "Health and medicine\n",
      "Main article: Artificial intelligence in healthcare\n",
      "\n",
      "The application of AI in medicine and medical research has the potential to increase patient care and quality of life.[129] Through the lens of the Hippocratic Oath, medical professionals are ethically compelled to use AI, if applications can more accurately diagnose and treat patients.\n",
      "\n",
      "For medical research, AI is an important tool for processing and integrating big data. This is particularly important for organoid and tissue engineering development which use microscopy imaging as a key technique in fabrication.[130] It has been suggested that AI can overcome discrepancies in funding allocated to different fields of research.[130] New AI tools can deepen the understanding of biomedically relevant pathways. For example, AlphaFold 2 (2021) demonstrated the ability to approximate, in hours rather than months, the 3D structure of a protein.[131] In 2023, it was reported that AI-guided drug discovery helped find a class of antibiotics capable of killing two different types of drug-resistant bacteria.[132] In 2024, researchers used machine learning to accelerate the search for Parkinson's disease drug treatments. Their aim was to identify compounds that block the clumping, or aggregation, of alpha-synuclein (the protein that characterises Parkinson's disease). They were able to speed up the initial screening process ten-fold and reduce the cost by a thousand-fold.[133][134]\n",
      "\n",
      "Games\n",
      "Main article: Game artificial intelligence\n",
      "\n",
      "Game playing programs have been used since the 1950s to demonstrate and test AI's most advanced techniques.[135] Deep Blue became the first computer chess-playing system to beat a reigning world chess champion, Garry Kasparov, on 11 May 1997.[136] In 2011, in a Jeopardy! quiz show exhibition match, IBM's question answering system, Watson, defeated the two greatest Jeopardy! champions, Brad Rutter and Ken Jennings, by a significant margin.[137] In March 2016, AlphaGo won 4 out of 5 games of Go in a match with Go champion Lee Sedol, becoming the first computer Go-playing system to beat a professional Go player without handicaps. Then, in 2017, it defeated Ke Jie, who was the best Go player in the world.[138] Other programs handle imperfect-information games, such as the poker-playing program Pluribus.[139] DeepMind developed increasingly generalistic reinforcement learning models, such as with MuZero, which could be trained to play chess, Go, or Atari games.[140] In 2019, DeepMind's AlphaStar achieved grandmaster level in StarCraft II, a particularly challenging real-time strategy game that involves incomplete knowledge of what happens on the map.[141] In 2021, an AI agent competed in a PlayStation Gran Turismo competition, winning against four of the world's best Gran Turismo drivers using deep reinforcement learning.[142] In 2024, Google DeepMind introduced SIMA, a type of AI capable of autonomously playing nine previously unseen open-world video games by observing screen output, as well as executing short, specific tasks in response to natural language instructions.[143]\n",
      "\n",
      "Mathematics\n",
      "\n",
      "In mathematics, special forms of formal step-by-step reasoning are used. In contrast, LLMs such as GPT-4 Turbo, Gemini Ultra, Claude Opus, LLaMa-2 or Mistral Large are working with probabilistic models, which can produce wrong answers in the form of hallucinations. Therefore, they need not only a large database of mathematical problems to learn from but also methods such as supervised fine-tuning or trained classifiers with human-annotated data to improve answers for new problems and learn from corrections.[144] A 2024 study showed that the performance of some language models for reasoning capabilities in solving math problems not included in their training data was low, even for problems with only minor deviations from trained data.[145]\n",
      "\n",
      "Alternatively, dedicated models for mathematic problem solving with higher precision for the outcome including proof of theorems have been developed such as Alpha Tensor, Alpha Geometry and Alpha Proof all from Google DeepMind,[146] Llemma from eleuther[147] or Julius.[148]\n",
      "\n",
      "When natural language is used to describe mathematical problems, converters transform such prompts into a formal language such as Lean to define mathematic tasks.\n",
      "\n",
      "Some models have been developed to solve challenging problems and reach good results in benchmark tests, others to serve as educational tools in mathematics.[149]\n",
      "\n",
      "Finance\n",
      "\n",
      "Finance is one of the fastest growing sectors where applied AI tools are being deployed: from retail online banking to investment advice and insurance, where automated \"robot advisers\" have been in use for some years.\n",
      "Score: 0.8435397077628686\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Content: Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[358][357]\n",
      "\n",
      "Future\n",
      "Superintelligence and the singularity\n",
      "\n",
      "A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[347]\n",
      "\n",
      "If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[364]\n",
      "\n",
      "However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.[365]\n",
      "\n",
      "Transhumanism\n",
      "\n",
      "Robot designer Hans Moravec, cyberneticist Kevin Warwick, and inventor Ray Kurzweil have predicted that humans and machines will merge in the future into cyborgs that are more capable and powerful than either. This idea, called transhumanism, has roots in Aldous Huxley and Robert Ettinger.[366]\n",
      "\n",
      "Edward Fredkin argues that \"artificial intelligence is the next stage in evolution\", an idea first proposed by Samuel Butler's \"Darwin among the Machines\" as far back as 1863, and expanded upon by George Dyson in his 1998 book Darwin Among the Machines: The Evolution of Global Intelligence.[367]\n",
      "\n",
      "In fiction\n",
      "Main article: Artificial intelligence in fiction\n",
      "The word \"robot\" itself was coined by Karel Čapek in his 1921 play R.U.R., the title standing for \"Rossum's Universal Robots\".\n",
      "\n",
      "Thought-capable artificial beings have appeared as storytelling devices since antiquity,[368] and have been a persistent theme in science fiction.[369]\n",
      "\n",
      "A common trope in these works began with Mary Shelley's Frankenstein, where a human creation becomes a threat to its masters. This includes such works as Arthur C. Clarke's and Stanley Kubrick's 2001: A Space Odyssey (both 1968), with HAL 9000, the murderous computer in charge of the Discovery One spaceship, as well as The Terminator (1984) and The Matrix (1999). In contrast, the rare loyal robots such as Gort from The Day the Earth Stood Still (1951) and Bishop from Aliens (1986) are less prominent in popular culture.[370]\n",
      "\n",
      "Isaac Asimov introduced the Three Laws of Robotics in many stories, most notably with the \"Multivac\" super-intelligent computer. Asimov's laws are often brought up during lay discussions of machine ethics;[371] while almost all artificial intelligence researchers are familiar with Asimov's laws through popular culture, they generally consider the laws useless for many reasons, one of which is their ambiguity.[372]\n",
      "\n",
      "Several works use AI to force us to confront the fundamental question of what makes us human, showing us artificial beings that have the ability to feel, and thus to suffer. This appears in Karel Čapek's R.U.R., the films A.I. Artificial Intelligence and Ex Machina, as well as the novel Do Androids Dream of Electric Sheep?, by Philip K. Dick. Dick considers the idea that our understanding of human subjectivity is altered by technology created with artificial intelligence.\n",
      "Score: 0.8530394176768973\n",
      "--------------------------------------------------\n",
      "Result 4:\n",
      "Content: This issue considers the internal experiences of the machine, rather than its external behavior. Mainstream AI research considers this issue irrelevant because it does not affect the goals of the field: to build machines that can solve problems using intelligence. Russell and Norvig add that \"[t]he additional project of making a machine conscious in exactly the way humans are is not one that we are equipped to take on.\"[348] However, the question has become central to the philosophy of mind. It is also typically the central question at issue in artificial intelligence in fiction.\n",
      "\n",
      "Consciousness\n",
      "Main articles: Hard problem of consciousness and Theory of mind\n",
      "\n",
      "David Chalmers identified two problems in understanding the mind, which he named the \"hard\" and \"easy\" problems of consciousness.[349] The easy problem is understanding how the brain processes signals, makes plans and controls behavior. The hard problem is explaining how this feels or why it should feel like anything at all, assuming we are right in thinking that it truly does feel like something (Dennett's consciousness illusionism says this is an illusion). While human information processing is easy to explain, human subjective experience is difficult to explain. For example, it is easy to imagine a color-blind person who has learned to identify which objects in their field of view are red, but it is not clear what would be required for the person to know what red looks like.[350]\n",
      "\n",
      "Computationalism and functionalism\n",
      "Main articles: Computational theory of mind, Functionalism (philosophy of mind), and Chinese room\n",
      "\n",
      "Computationalism is the position in the philosophy of mind that the human mind is an information processing system and that thinking is a form of computing. Computationalism argues that the relationship between mind and body is similar or identical to the relationship between software and hardware and thus may be a solution to the mind–body problem. This philosophical position was inspired by the work of AI researchers and cognitive scientists in the 1960s and was originally proposed by philosophers Jerry Fodor and Hilary Putnam.[351]\n",
      "\n",
      "Philosopher John Searle characterized this position as \"strong AI\": \"The appropriately programmed computer with the right inputs and outputs would thereby have a mind in exactly the same sense human beings have minds.\"[ac] Searle counters this assertion with his Chinese room argument, which attempts to show that, even if a machine perfectly simulates human behavior, there is still no reason to suppose it also has a mind.[355]\n",
      "\n",
      "AI welfare and rights\n",
      "\n",
      "It is difficult or impossible to reliably evaluate whether an advanced AI is sentient (has the ability to feel), and if so, to what degree.[356] But if there is a significant chance that a given machine can feel and suffer, then it may be entitled to certain rights or welfare protection measures, similarly to animals.[357][358] Sapience (a set of capacities related to high intelligence, such as discernment or self-awareness) may provide another moral basis for AI rights.[357] Robot rights are also sometimes proposed as a practical way to integrate autonomous agents into society.[359]\n",
      "\n",
      "In 2017, the European Union considered granting \"electronic personhood\" to some of the most capable AI systems. Similarly to the legal status of companies, it would have conferred rights but also responsibilities.[360] Critics argued in 2018 that granting rights to AI systems would downplay the importance of human rights, and that legislation should focus on user needs rather than speculative futuristic scenarios. They also noted that robots lacked the autonomy to take part to society on their own.[361][362] In 2019, Soenke Ziesche and Roman Yampolskiy coined the term “AI welfare” and outlined the new field of AI welfare science, which is derived from animal welfare science.[363]\n",
      "\n",
      "Progress in AI increased interest in the topic. Proponents of AI welfare and rights often argue that AI sentience, if it emerges, would be particularly easy to deny. They warn that this may be a moral blind spot analogous to slavery or factory farming, which could lead to large-scale suffering if sentient AI is created and carelessly exploited.[358][357]\n",
      "\n",
      "Future\n",
      "Superintelligence and the singularity\n",
      "\n",
      "A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.[347]\n",
      "\n",
      "If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an \"intelligence explosion\" and Vernor Vinge called a \"singularity\".[364]\n",
      "\n",
      "However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.\n",
      "Score: 0.8476219155275916\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: How to create a agent using yaml in CrewAI?\n",
      "Retrieved parent IDs from level 2: ['1de596a1-366f-4f6a-8a01-aa2cbd9f229c']\n",
      "Retrieved 1 from parents at level 2.\n",
      "Retrieved parent IDs from level 1: ['e60b28b2-2912-4188-9fee-171ce9884405']\n",
      "Retrieved 2 from parents at level 1.\n",
      "Retrieved parent IDs from level 0: ['88bc9061-3f3d-4738-9d5a-eca1065fe47b', '7beb3904-daac-4a60-af65-bde29b5db54b']\n",
      "Retrieved 4 from parents at level 0.\n",
      "Result 1:\n",
      "Content: For example, you can reference the agent for specific tasks from task.yaml file. Ensure your annotated agent and function name is the same otherwise your task won't recognize the reference properly.\n",
      "\n",
      "#### Example References[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#example-references \"Permanent link\")\n",
      "\n",
      "agent.yaml\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-1)email_summarizer:\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-2)role:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-3)Email Summarizer\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-4)goal:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-5)Summarize emails into a concise and clear summary\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-6)backstory:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-7)You will create a 5 bullet point summary of the report\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-5-8)llm:mixtal_llm\n",
      "```\n",
      "\n",
      "task.yaml\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-1)email_summarizer_task:\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-2)description:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-3)Summarize the email into a 5 bullet point summary\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-4)expected_output:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-5)A 5 bullet point summary of the email\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-6)agent:email_summarizer\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-7)context:\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-8)-reporting_task\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-6-9)-research_task\n",
      "```\n",
      "\n",
      "Use the annotations to properly reference the agent and task in the crew.py file.\n",
      "\n",
      "### Annotations include:[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#annotations-include \"Permanent link\")\n",
      "\n",
      "*   [@agent](https://github.com/crewAIInc/crewAI/blob/97d7bfb52ad49a9f04db360e1b6612d98c91971e/src/crewai/project/annotations.py#L17)\n",
      "*   [@task](https://github.com/crewAIInc/crewAI/blob/97d7bfb52ad49a9f04db360e1b6612d98c91971e/src/crewai/project/annotations.py#L4)\n",
      "*   [@crew](https://github.\n",
      "Score: 0.8456336330278614\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Content: The `main.py` file is the entry point of your project, and the `crew.py` file is where you define your agents and tasks.\n",
      "\n",
      "Customizing Your Project[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#customizing-your-project \"Permanent link\")\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "To customize your project, you can: - Modify `src/my_project/config/agents.yaml` to define your agents. - Modify `src/my_project/config/tasks.yaml` to define your tasks. - Modify `src/my_project/crew.py` to add your own logic, tools, and specific arguments. - Modify `src/my_project/main.py` to add custom inputs for your agents and tasks. - Add your environment variables into the `.env` file.\n",
      "\n",
      "### Example: Defining Agents and Tasks[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#example-defining-agents-and-tasks \"Permanent link\")\n",
      "\n",
      "#### agents.yaml[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#agentsyaml \"Permanent link\")\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-1)researcher:\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-2)role:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-3)Job Candidate Researcher\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-4)goal:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-5)Find potential candidates for the job\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-6)backstory:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-7)You are adept at finding the right candidates by exploring various online\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-8)resources. Your skill in identifying suitable candidates ensures the best\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-3-9)match for job positions.\n",
      "```\n",
      "\n",
      "#### tasks.yaml[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#tasksyaml \"Permanent link\")\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-4-1)research_candidates_task:\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-4-2)description:>\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-4-3)Conduct thorough research to find potential candidates for the specified job.\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-4-4)Utilize various online resources and databases to gather a comprehensive list of potential candidates.\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-4-5)Ensure that the candidates meet the job requirements provided.\n",
      "Score: 0.8407381000885378\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Content: [173][174] Website owners who do not wish to have their content scraped can indicate it in a \"robots.txt\" file.[175] In 2023, leading authors (including John Grisham and Jonathan Franzen) sued AI companies for using their work to train generative AI.[176][177] Another discussed approach is to envision a separate sui generis system of protection for creations generated by AI to ensure fair attribution and compensation for human authors.[178]\n",
      "\n",
      "Dominance by tech giants\n",
      "\n",
      "The commercial AI scene is dominated by Big Tech companies such as Alphabet Inc., Amazon, Apple Inc., Meta Platforms, and Microsoft.[179][180][181] Some of these players already own the vast majority of existing cloud infrastructure and computing power from data centers, allowing them to entrench further in the marketplace.[182][183]\n",
      "\n",
      "Substantial power needs and other environmental impacts\n",
      "See also: Environmental impacts of artificial intelligence\n",
      "\n",
      "In January 2024, the International Energy Agency (IEA) released Electricity 2024, Analysis and Forecast to 2026, forecasting electric power use.[184] This is the first IEA report to make projections for data centers and power consumption for artificial intelligence and cryptocurrency. The report states that power demand for these uses might double by 2026, with additional electric power usage equal to electricity used by the whole Japanese nation.[185]\n",
      "\n",
      "Prodigious power consumption by AI is responsible for the growth of fossil fuels use, and might delay closings of obsolete, carbon-emitting coal energy facilities. There is a feverish rise in the construction of data centers throughout the US, making large technology firms (e.g., Microsoft, Meta, Google, Amazon) into voracious consumers of electric power. Projected electric consumption is so immense that there is concern that it will be fulfilled no matter the source. A ChatGPT search involves the use of 10 times the electrical energy as a Google search. The large firms are in haste to find power sources – from nuclear energy to geothermal to fusion. The tech firms argue that – in the long view – AI will be eventually kinder to the environment, but they need the energy now. AI makes the power grid more efficient and \"intelligent\", will assist in the growth of nuclear power, and track overall carbon emissions, according to technology firms.[186]\n",
      "\n",
      "A 2024 Goldman Sachs Research Paper, AI Data Centers and the Coming US Power Demand Surge, found \"US power demand (is) likely to experience growth not seen in a generation….\" and forecasts that, by 2030, US data centers will consume 8% of US power, as opposed to 3% in 2022, presaging growth for the electrical power generation industry by a variety of means.[187]Data centers' need for more and more electrical power is such that they might max out the electrical grid. The Big Tech companies counter that AI can be used to maximize the utilization of the grid by all.[188]\n",
      "\n",
      "In 2024, the Wall Street Journal reported that big AI companies have begun negotiations with the US nuclear power providers to provide electricity to the data centers. In March 2024 Amazon purchased a Pennsylvania nuclear-powered data center for $650 Million (US).[189]\n",
      "\n",
      "Misinformation\n",
      "See also: YouTube § Moderation and offensive content\n",
      "\n",
      "YouTube, Facebook and others use recommender systems to guide users to more content. These AI programs were given the goal of maximizing user engagement (that is, the only goal was to keep people watching). The AI learned that users tended to choose misinformation, conspiracy theories, and extreme partisan content, and, to keep them watching, the AI recommended more of it. Users also tended to watch more content on the same subject, so the AI led people into filter bubbles where they received multiple versions of the same misinformation.[190] This convinced many users that the misinformation was true, and ultimately undermined trust in institutions, the media and the government.[191] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem [citation needed].\n",
      "\n",
      "In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films, or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[192] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[193]\n",
      "\n",
      "Algorithmic bias and fairness\n",
      "Main articles: Algorithmic bias and Fairness (machine learning)\n",
      "\n",
      "Machine learning applications will be biased[k] if they learn from biased data.[195] The developers may not be aware that the bias exists.\n",
      "Score: 0.724544475610309\n",
      "--------------------------------------------------\n",
      "Result 4:\n",
      "Content: [191] The AI program had correctly learned to maximize its goal, but the result was harmful to society. After the U.S. election in 2016, major technology companies took steps to mitigate the problem [citation needed].\n",
      "\n",
      "In 2022, generative AI began to create images, audio, video and text that are indistinguishable from real photographs, recordings, films, or human writing. It is possible for bad actors to use this technology to create massive amounts of misinformation or propaganda.[192] AI pioneer Geoffrey Hinton expressed concern about AI enabling \"authoritarian leaders to manipulate their electorates\" on a large scale, among other risks.[193]\n",
      "\n",
      "Algorithmic bias and fairness\n",
      "Main articles: Algorithmic bias and Fairness (machine learning)\n",
      "\n",
      "Machine learning applications will be biased[k] if they learn from biased data.[195] The developers may not be aware that the bias exists.[196] Bias can be introduced by the way training data is selected and by the way a model is deployed.[197][195] If a biased algorithm is used to make decisions that can seriously harm people (as it can in medicine, finance, recruitment, housing or policing) then the algorithm may cause discrimination.[198] The field of fairness studies how to prevent harms from algorithmic biases.\n",
      "\n",
      "On June 28, 2015, Google Photos's new image labeling feature mistakenly identified Jacky Alcine and a friend as \"gorillas\" because they were black. The system was trained on a dataset that contained very few images of black people,[199] a problem called \"sample size disparity\".[200] Google \"fixed\" this problem by preventing the system from labelling anything as a \"gorilla\". Eight years later, in 2023, Google Photos still could not identify a gorilla, and neither could similar products from Apple, Facebook, Microsoft and Amazon.[201]\n",
      "\n",
      "COMPAS is a commercial program widely used by U.S. courts to assess the likelihood of a defendant becoming a recidivist. In 2016, Julia Angwin at ProPublica discovered that COMPAS exhibited racial bias, despite the fact that the program was not told the races of the defendants. Although the error rate for both whites and blacks was calibrated equal at exactly 61%, the errors for each race were different—the system consistently overestimated the chance that a black person would re-offend and would underestimate the chance that a white person would not re-offend.[202] In 2017, several researchers[l] showed that it was mathematically impossible for COMPAS to accommodate all possible measures of fairness when the base rates of re-offense were different for whites and blacks in the data.[204]\n",
      "\n",
      "A program can make biased decisions even if the data does not explicitly mention a problematic feature (such as \"race\" or \"gender\"). The feature will correlate with other features (like \"address\", \"shopping history\" or \"first name\"), and the program will make the same decisions based on these features as it would on \"race\" or \"gender\".[205] Moritz Hardt said \"the most robust fact in this research area is that fairness through blindness doesn't work.\"[206]\n",
      "\n",
      "Criticism of COMPAS highlighted that machine learning models are designed to make \"predictions\" that are only valid if we assume that the future will resemble the past. If they are trained on data that includes the results of racist decisions in the past, machine learning models must predict that racist decisions will be made in the future. If an application then uses these predictions as recommendations, some of these \"recommendations\" will likely be racist.[207] Thus, machine learning is not well suited to help make decisions in areas where there is hope that the future will be better than the past. It is descriptive rather than prescriptive.[m]\n",
      "\n",
      "Bias and unfairness may go undetected because the developers are overwhelmingly white and male: among AI engineers, about 4% are black and 20% are women.[200]\n",
      "\n",
      "There are various conflicting definitions and mathematical models of fairness. These notions depend on ethical assumptions, and are influenced by beliefs about society. One broad category is distributive fairness, which focuses on the outcomes, often identifying groups and seeking to compensate for statistical disparities. Representational fairness tries to ensure that AI systems do not reinforce negative stereotypes or render certain groups invisible. Procedural fairness focuses on the decision process rather than the outcome. The most relevant notions of fairness may depend on the context, notably the type of AI application and the stakeholders. The subjectivity in the notions of bias and fairness makes it difficult for companies to operationalize them. Having access to sensitive attributes such as race or gender is also considered by many AI ethicists to be necessary in order to compensate for biases, but it may conflict with anti-discrimination laws.\n",
      "Score: 0.7163460963583902\n",
      "--------------------------------------------------\n",
      "\n",
      "Query: How to achieve AGI?\n",
      "Retrieved parent IDs from level 2: ['1de596a1-366f-4f6a-8a01-aa2cbd9f229c']\n",
      "Retrieved 1 from parents at level 2.\n",
      "Retrieved parent IDs from level 1: ['e60b28b2-2912-4188-9fee-171ce9884405']\n",
      "Retrieved 2 from parents at level 1.\n",
      "Retrieved parent IDs from level 0: ['88bc9061-3f3d-4738-9d5a-eca1065fe47b', '7dd18d42-50de-4dd8-a12f-6a592f6cc10a']\n",
      "Retrieved 4 from parents at level 0.\n",
      "Result 1:\n",
      "Content: You can use any code IDE of your choice. See below for some popular options for Code Editors / Integrated Development Environments (IDE):\n",
      "\n",
      "*   [Visual Studio Code](https://code.visualstudio.com/) - Most popular\n",
      "*   [PyCharm](https://www.jetbrains.com/pycharm/)\n",
      "*   [Cursor AI](https://cursor.com/)\n",
      "\n",
      "Pick one that suits your style and needs.\n",
      "\n",
      "Creating a New Project[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#creating-a-new-project \"Permanent link\")\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "In this example, we will be using Venv as our virtual environment manager.\n",
      "\n",
      "To set up a virtual environment, run the following CLI command: To create a new CrewAI project, run the following CLI command:\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-1-1)$crewaicreatecrew<project_name>\n",
      "```\n",
      "\n",
      "This command will create a new project folder with the following structure:\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-1)my_project/\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-2)├──.gitignore\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-3)├──pyproject.toml\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-4)├──README.md\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-5)└──src/\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-6)└──my_project/\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-7)├──__init__.py\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-8)├──main.py\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-9)├──crew.py\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-10)├──tools/\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-11)│├──custom_tool.py\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-12)│└──__init__.py\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-13)└──config/\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-14)├──agents.yaml\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-2-15)└──tasks.yaml\n",
      "```\n",
      "\n",
      "You can now start developing your project by editing the files in the `src/my_project` folder. The `main.py` file is the entry point of your project, and the `crew.py` file is where you define your agents and tasks.\n",
      "\n",
      "Customizing Your Project[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#customizing-your-project \"Permanent link\")\n",
      "----------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "To customize your project, you can: - Modify `src/my_project/config/agents.yaml` to define your agents. - Modify `src/my_project/config/tasks.yaml` to define your tasks.\n",
      "Score: 0.7356594918672401\n",
      "--------------------------------------------------\n",
      "Result 2:\n",
      "Content: Title: Starting a New CrewAI Project - Using Template - crewAI\n",
      "\n",
      "URL Source: https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/\n",
      "\n",
      "Markdown Content:\n",
      "[](https://github.com/joaomdmoura/crewai/edit/main/docs/getting-started/Start-a-New-CrewAI-Project-Template-Method.md \"Edit this page\")[](https://github.com/joaomdmoura/crewai/raw/main/docs/getting-started/Start-a-New-CrewAI-Project-Template-Method.md \"View source of this page\")Welcome to the ultimate guide for starting a new CrewAI project. This document will walk you through the steps to create, customize, and run your CrewAI project, ensuring you have everything you need to get started.\n",
      "\n",
      "Before we start, there are a couple of things to note:\n",
      "\n",
      "1.  CrewAI is a Python package and requires Python >=3.10 and <=3.13 to run.\n",
      "2.  The preferred way of setting up CrewAI is using the `crewai create crew` command. This will create a new project folder and install a skeleton template for you to work on.\n",
      "\n",
      "Prerequisites[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#prerequisites \"Permanent link\")\n",
      "------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "Before getting started with CrewAI, make sure that you have installed it via pip:\n",
      "\n",
      "```\n",
      "[](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#__codelineno-0-1)$pipinstallcrewaicrewai-tools\n",
      "```\n",
      "\n",
      "### Virtual Environments[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#virtual-environments \"Permanent link\")\n",
      "\n",
      "It is highly recommended that you use virtual environments to ensure that your CrewAI project is isolated from other projects and dependencies. Virtual environments provide a clean, separate workspace for each project, preventing conflicts between different versions of packages and libraries. This isolation is crucial for maintaining consistency and reproducibility in your development process. You have multiple options for setting up virtual environments depending on your operating system and Python version:\n",
      "\n",
      "1.  Use venv (Python's built-in virtual environment tool): venv is included with Python 3.3 and later, making it a convenient choice for many developers. It's lightweight and easy to use, perfect for simple project setups.\n",
      "\n",
      "To set up virtual environments with venv, refer to the official [Python documentation](https://docs.python.org/3/tutorial/venv.html).\n",
      "\n",
      "1.  Use Conda (A Python virtual environment manager): Conda is an open-source package manager and environment management system for Python. It's widely used by data scientists, developers, and researchers to manage dependencies and environments in a reproducible way.\n",
      "\n",
      "To set up virtual environments with Conda, refer to the official [Conda documentation](https://docs.conda.io/projects/conda/en/stable/user-guide/getting-started.html).\n",
      "\n",
      "1.  Use Poetry (A Python package manager and dependency management tool): Poetry is an open-source Python package manager that simplifies the installation of packages and their dependencies. Poetry offers a convenient way to manage virtual environments and dependencies. Poetry is CrewAI's preferred tool for package / dependency management in CrewAI.\n",
      "\n",
      "### Code IDEs[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#code-ides \"Permanent link\")\n",
      "\n",
      "Most users of CrewAI use a Code Editor / Integrated Development Environment (IDE) for building their Crews. You can use any code IDE of your choice. See below for some popular options for Code Editors / Integrated Development Environments (IDE):\n",
      "\n",
      "*   [Visual Studio Code](https://code.visualstudio.com/) - Most popular\n",
      "*   [PyCharm](https://www.jetbrains.com/pycharm/)\n",
      "*   [Cursor AI](https://cursor.com/)\n",
      "\n",
      "Pick one that suits your style and needs.\n",
      "\n",
      "Creating a New Project[¶](https://docs.crewai.com/getting-started/Start-a-New-CrewAI-Project-Template-Method/#creating-a-new-project \"Permanent link\")\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n",
      "In this example, we will be using Venv as our virtual environment manager.\n",
      "Score: 0.7255070505655441\n",
      "--------------------------------------------------\n",
      "Result 3:\n",
      "Content: Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[281]\n",
      "\n",
      "In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[258]\n",
      "\n",
      "In the late teens and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program was taught only the rules of the game and developed strategy by itself. GPT-3 is a large language model that was released in 2020 by OpenAI and is capable of generating high-quality human-like text.[324] These programs, and others, inspired an aggressive AI boom, where large companies began investing billions in AI research. According to AI Impacts, about $50 billion annually was invested in \"AI\" around 2022 in the U.S. alone and about 20% of the new U.S. Computer Science PhD graduates have specialized in \"AI\".[325] About 800,000 \"AI\"-related U.S. job openings existed in 2022.[326]\n",
      "\n",
      "Philosophy\n",
      "Main article: Philosophy of artificial intelligence\n",
      "Defining artificial intelligence\n",
      "See also: Turing test, Intelligent agent, Dartmouth workshop, and Synthetic intelligence\n",
      "\n",
      "Alan Turing wrote in 1950 \"I propose to consider the question 'can machines think'?\"[327] He advised changing the question from whether a machine \"thinks\", to \"whether or not it is possible for machinery to show intelligent behaviour\".[327] He devised the Turing test, which measures the ability of a machine to simulate human conversation.[297] Since we can only observe the behavior of the machine, it does not matter if it is \"actually\" thinking or literally has a \"mind\". Turing notes that we can not determine these things about other people but \"it is usual to have a polite convention that everyone thinks.\"[328]\n",
      "\n",
      "The Turing test can provide some evidence of intelligence, but it penalizes non-human intelligent behavior.[329]\n",
      "\n",
      "Russell and Norvig agree with Turing that intelligence must be defined in terms of external behavior, not internal structure.[1] However, they are critical that the test requires the machine to imitate humans. \"Aeronautical engineering texts,\" they wrote, \"do not define the goal of their field as making 'machines that fly so exactly like pigeons that they can fool other pigeons.'\"[330] AI founder John McCarthy agreed, writing that \"Artificial intelligence is not, by definition, simulation of human intelligence\".[331]\n",
      "\n",
      "McCarthy defines intelligence as \"the computational part of the ability to achieve goals in the world\".[332] Another AI founder, Marvin Minsky similarly describes it as \"the ability to solve hard problems\".[333] The leading AI textbook defines it as the study of agents that perceive their environment and take actions that maximize their chances of achieving defined goals.[1] These definitions view intelligence in terms of well-defined problems with well-defined solutions, where both the difficulty of the problem and the performance of the program are direct measures of the \"intelligence\" of the machine—and no other philosophical discussion is required, or may not even be possible.\n",
      "\n",
      "Another definition has been adopted by Google,[334] a major practitioner in the field of AI. This definition stipulates the ability of systems to synthesize information as the manifestation of intelligence, similar to the way it is defined in biological intelligence.\n",
      "\n",
      "Some authors have suggested in practice, that the definition of AI is vague and difficult to define, with contention as to whether classical algorithms should be categorised as AI,[335] with many companies during the early 2020s AI boom using the term as a marketing buzzword, often even if they did \"not actually use AI in a material way\".[336]\n",
      "\n",
      "Evaluating approaches to AI\n",
      "\n",
      "No established unifying theory or paradigm has guided AI research for most of its history.[aa] The unprecedented success of statistical machine learning in the 2010s eclipsed all other approaches (so much so that some sources, especially in the business world, use the term \"artificial intelligence\" to mean \"machine learning with neural networks\"). This approach is mostly sub-symbolic, soft and narrow. Critics argue that these questions may have to be revisited by future generations of AI researchers.\n",
      "\n",
      "Symbolic AI and its limits\n",
      "\n",
      "Symbolic AI (or \"GOFAI\")[338] simulated the high-level conscious reasoning that people use when they solve puzzles, express legal reasoning and do mathematics. They were highly successful at \"intelligent\" tasks such as algebra or IQ tests.\n",
      "Score: 0.7532762633143146\n",
      "--------------------------------------------------\n",
      "Result 4:\n",
      "Content: universities in the latter 1950s and early 1960s.[294]\n",
      "\n",
      "Researchers in the 1960s and the 1970s were convinced that their methods would eventually succeed in creating a machine with general intelligence and considered this the goal of their field.[301] In 1965 Herbert Simon predicted, \"machines will be capable, within twenty years, of doing any work a man can do\".[302] In 1967 Marvin Minsky agreed, writing, \"within a generation ... the problem of creating 'artificial intelligence' will substantially be solved\".[303] They had, however, underestimated the difficulty of the problem.[w] In 1974, both the U.S. and British governments cut off exploratory research in response to the criticism of Sir James Lighthill[305] and ongoing pressure from the U.S. Congress to fund more productive projects.[306] Minsky's and Papert's book Perceptrons was understood as proving that artificial neural networks would never be useful for solving real-world tasks, thus discrediting the approach altogether.[307] The \"AI winter\", a period when obtaining funding for AI projects was difficult, followed.[9]\n",
      "\n",
      "In the early 1980s, AI research was revived by the commercial success of expert systems,[308] a form of AI program that simulated the knowledge and analytical skills of human experts. By 1985, the market for AI had reached over a billion dollars. At the same time, Japan's fifth generation computer project inspired the U.S. and British governments to restore funding for academic research.[8] However, beginning with the collapse of the Lisp Machine market in 1987, AI once again fell into disrepute, and a second, longer-lasting winter began.[10]\n",
      "\n",
      "Up to this point, most of AI's funding had gone to projects that used high-level symbols to represent mental objects like plans, goals, beliefs, and known facts. In the 1980s, some researchers began to doubt that this approach would be able to imitate all the processes of human cognition, especially perception, robotics, learning and pattern recognition,[309] and began to look into \"sub-symbolic\" approaches.[310] Rodney Brooks rejected \"representation\" in general and focussed directly on engineering machines that move and survive.[x] Judea Pearl, Lofti Zadeh and others developed methods that handled incomplete and uncertain information by making reasonable guesses rather than precise logic.[86][315] But the most important development was the revival of \"connectionism\", including neural network research, by Geoffrey Hinton and others.[316] In 1990, Yann LeCun successfully showed that convolutional neural networks can recognize handwritten digits, the first of many successful applications of neural networks.[317]\n",
      "\n",
      "AI gradually restored its reputation in the late 1990s and early 21st century by exploiting formal mathematical methods and by finding specific solutions to specific problems. This \"narrow\" and \"formal\" focus allowed researchers to produce verifiable results and collaborate with other fields (such as statistics, economics and mathematics).[318] By 2000, solutions developed by AI researchers were being widely used, although in the 1990s they were rarely described as \"artificial intelligence\".[319] However, several academic researchers became concerned that AI was no longer pursuing its original goal of creating versatile, fully intelligent machines. Beginning around 2002, they founded the subfield of artificial general intelligence (or \"AGI\"), which had several well-funded institutions by the 2010s.[4]\n",
      "\n",
      "Deep learning began to dominate industry benchmarks in 2012 and was adopted throughout the field.[11] For many specific tasks, other methods were abandoned.[y] Deep learning's success was based on both hardware improvements (faster computers,[321] graphics processing units, cloud computing[322]) and access to large amounts of data[323] (including curated datasets,[322] such as ImageNet). Deep learning's success led to an enormous increase in interest and funding in AI.[z] The amount of machine learning research (measured by total publications) increased by 50% in the years 2015–2019.[281]\n",
      "\n",
      "In 2016, issues of fairness and the misuse of technology were catapulted into center stage at machine learning conferences, publications vastly increased, funding became available, and many researchers re-focussed their careers on these issues. The alignment problem became a serious field of academic study.[258]\n",
      "\n",
      "In the late teens and early 2020s, AGI companies began to deliver programs that created enormous interest. In 2015, AlphaGo, developed by DeepMind, beat the world champion Go player. The program was taught only the rules of the game and developed strategy by itself.\n",
      "Score: 0.7517285384716524\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "documents = create_sample_documents()\n",
    "\n",
    "# Initialize RaptorPack\n",
    "raptor_pack = RaptorPack(\n",
    "    documents,\n",
    "    llm=OpenAI(model=\"gpt-4o-mini\"),\n",
    "    embed_model=OpenAIEmbedding(),\n",
    "    similarity_top_k=2,\n",
    "    mode=QueryModes.tree_traversal,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Test queries\n",
    "queries = [\n",
    "    \"What is artificial intelligence?\",\n",
    "    \"How to create a agent using yaml in CrewAI?\",\n",
    "    \"How to achieve AGI?\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    print(f\"\\nQuery: {query}\")\n",
    "    results = raptor_pack.run(query)\n",
    "    for i, node in enumerate(results, 1):\n",
    "        print(f\"Result {i}:\")\n",
    "        print(f\"Content: {node.node.get_content()}\")\n",
    "        print(f\"Score: {node.score}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cognitivelab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
