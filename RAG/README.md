# RAG (Retrieval Augmented Generation) System

RAG has become increasingly popular in the field of natural language processing and machine learning. This README outlines the tech stack and approach for systematically improving a RAG system.

## Tech Stack

### RAG Orchestration Framework

- **Llama-index**

### Vector Database

- **Qdrant**

### Observability

- **Arize Phoenix**

### Evaluation

- **RAGAS**
- **Deepeval**

### Language Models

- **LLM of Choice:** GPT-4-mini
- **Embedding Model:** text-embedding-3-small

## Systematically Improving RAG

To enhance the performance of our RAG system, we will focus on the following areas:

1. **Data Quality**: Ensure high-quality, diverse, and relevant data for training and retrieval.

2. **Embedding Techniques**: Experiment with different embedding models and fine-tuning approaches.

3. **Retrieval Optimization**: Improve the retrieval process using techniques like hybrid search or re-ranking.

4. **Context Window Management**: Optimize the use of context windows for more effective generation.

5. **Prompt Engineering**: Develop and refine prompts to guide the LLM effectively.

6. **Fine-tuning**: Explore domain-specific fine-tuning of the LLM when applicable.

7. **Evaluation and Metrics**: Utilize RAGAS and Deepeval to assess performance and guide improvements.

8. **Observability**: Leverage Arize Phoenix to monitor system behavior and identify areas for optimization.

9. **Iterative Testing**: Continuously test and refine the system based on real-world usage and feedback.

10. **Scalability**: Optimize the system architecture to handle increased load and data volume efficiently.

By focusing on these areas and utilizing our chosen tech stack, we aim to create a robust and high-performing RAG system that delivers accurate and relevant results.
